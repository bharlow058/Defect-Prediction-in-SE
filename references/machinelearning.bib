% This file was created with JabRef 2.10.
% Encoding: ISO8859_1


@Article{Afzal2012IJSEKE,
  Title                    = {Resampling methods in software quality classification},
  Author                   = {Wasif Afzal and Richard Torkar and Robert Feldt},
  Journal                  = {International Journal of Software Engineering and Knowledge Engineering},
  Year                     = {2012},
  Pages                    = {203--223},
  Volume                   = {22},

  Issue                    = {2},
  Keywords                 = {Software quality; Prediction; Resampling; Empirical study},
  Publisher                = {World Scientific Publishing Company}
}

@Article{Alcala11,
  Title                    = {{KEEL} Data-Mining Software Tool: Data Set Repository, Integration of Algorithms and Experimental Analysis Framework},
  Author                   = {J. {Alcal\'a-Fdez} and A. Fernandez and J. Luengo and J. Derrac, S. Garc\'aa and L. S\'anchez and F. Herrera},
  Journal                  = {Journal of Multiple-Valued Logic and Soft Computing},
  Year                     = {2011},
  Number                   = {2-3},
  Pages                    = {255-287},
  Volume                   = {17}
}

@Article{Alcala09,
  Title                    = {{KEEL}: A Software Tool to Assess Evolutionary Algorithms to Data Mining Problems},
  Author                   = {J. {Alcal\'a-Fdez} and L. S\'anchez and S. Garc\'ia and M.J. del Jesus and S. Ventura and J.M. Garrell and J. Otero and C. Romero and J. Bacardit and V.M. Rivas and J.C. Fern\'andez and F. Herrera},
  Journal                  = {Soft Computing},
  Year                     = {2009},
  Number                   = {3},
  Pages                    = {307--318},
  Volume                   = {13}
}

@Article{Arisholm10,
  Title                    = {A systematic and comprehensive investigation of methods to build and evaluate fault prediction models},
  Author                   = {Erik Arisholm and Lionel C. Briand and Eivind B. Johannessen},
  Journal                  = {Journal of Systems and Software},
  Year                     = {2010},
  Number                   = {1},
  Pages                    = {2--17},
  Volume                   = {83},

  Address                  = {New York, NY, USA},
  Doi                      = {http://dx.doi.org/10.1016/j.jss.2009.06.055},
  ISSN                     = {0164-1212},
  Publisher                = {Elsevier Science Inc.}
}

@Article{Breiman96,
  Title                    = {Bagging predictors},
  Author                   = {Breiman, Leo},
  Journal                  = {Machine Learning},
  Year                     = {1996},
  Pages                    = {123-140},
  Volume                   = {24},

  Doi                      = {10.1007/BF00058655},
  ISSN                     = {0885-6125},
  Issue                    = {2},
  Keywords                 = {Aggregation; Bootstrap; Averaging; Combining},
  Language                 = {English},
  Publisher                = {Kluwer Academic Publishers},
  Url                      = {http://dx.doi.org/10.1007/BF00058655}
}

@Book{Breiman1984,
  Title                    = {Classification and Regression Trees},
  Author                   = {Leo Breiman and Jerome H. Friedman and Richard A. Olshen and Charles J. Stone},
  Publisher                = {Wadsworth International Group},
  Year                     = {1984},

  Address                  = {Belmont, California}
}

@InProceedings{buse-icse-2012,
  Title                    = {Information Needs for Software Development Analytics},
  Author                   = {Raymond P.L. Buse and Thomas Zimmermann},
  Booktitle                = {Proceedings of the 34th International Conference on Software Engineering},
  Year                     = {2012},
  Month                    = {June},

  Location                 = {Zurich, Switzerland}
}

@InProceedings{Caglayan09,
  Title                    = {Merits of using repository metrics in defect prediction for open source projects},
  Author                   = {Caglayan, Bora and Bener, Ayse and Koch, Stefan},
  Booktitle                = {Proceedings of the 2009 ICSE Workshop on Emerging Trends in Free/Libre/Open Source Software Research and Development},
  Year                     = {2009},

  Address                  = {Washington, DC, USA},
  Pages                    = {31--36},
  Publisher                = {IEEE Computer Society},
  Series                   = {FLOSS'09},

  Acmid                    = {1572199},
  Doi                      = {10.1109/FLOSS.2009.5071357},
  ISBN                     = {978-1-4244-3720-7},
  Numpages                 = {6},
  Url                      = {http://dx.doi.org/10.1109/FLOSS.2009.5071357}
}

@Article{Catal_WIRED12,
  Title                    = {Software mining and fault prediction},
  Author                   = {Catal, Cagatay},
  Journal                  = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  Year                     = {2012},
  Number                   = {5},
  Pages                    = {420--426},
  Volume                   = {2},

  Abstract                 = {Mining software repositories (MSRs) such as source control repositories, bug repositories, deployment logs, and code repositories provide useful patterns for practitioners. Instead of using these repositories as record-keeping ones, we need to transform them into active repositories that can guide the decision processes inside the company. By MSRs with several data mining algorithms, effective software fault prediction models can be built and error-prone modules can be detected prior to the testing phase. We discuss numerous real-world challenges in building accurate fault prediction models and present some solutions to these challenges. à¤Š 2012 Wiley Periodicals, Inc.},
  Doi                      = {10.1002/widm.1067},
  ISSN                     = {1942-4795},
  Publisher                = {John Wiley \& Sons, Inc.},
  Url                      = {http://dx.doi.org/10.1002/widm.1067}
}

@Article{CBHK2002,
  Title                    = {{SMOTE}: Synthetic Minority Over-sampling TEchnique},
  Author                   = {N.V. Chawla and K.W. Bowyer and L.O. Hall and W.P. Kegelmeyer},
  Journal                  = {Journal of Artificial Intelligence Research },
  Year                     = {2002},
  Pages                    = {321--357},
  Volume                   = {16}
}

@InProceedings{CLHB2003,
  Title                    = {SMOTEBoost: Improving prediction of the minority class in boosting},
  Author                   = {N.V. Chawla and A. Lazarevic and L.O. Hall and K.W. Bowyer},
  Booktitle                = {7th European Conference on Principles and Practice of Knowledge Discovery in Databases({PKDD 2003})},
  Year                     = {2003},
  Pages                    = {107--119},

  City                     = {Cavtat Dubrovnik},
  Country                  = {Croatia}
}

@Article{ChawlaBHK02,
  Title                    = {SMOTE: Synthetic Minority Over-sampling Technique},
  Author                   = {Nitesh V. Chawla and Kevin W. Bowyer and Lawrence O. Hall and W. Philip Kegelmeyer},
  Journal                  = {J. Artif. Intell. Res. (JAIR)},
  Year                     = {2002},
  Pages                    = {321--357},
  Volume                   = {16},

  Bibsource                = {DBLP, http://dblp.uni-trier.de},
  Ee                       = {http://dx.doi.org/10.1613/jair.953}
}

@Article{Demsar2006,
  Title                    = {Statistical Comparisons of Classifiers over Multiple Data Sets},
  Author                   = {Dem\v{s}ar, Janez},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2006},

  Month                    = dec,
  Pages                    = {1--30},
  Volume                   = {7},

  Acmid                    = {1248548},
  ISSN                     = {1532-4435},
  Issue_date               = {12/1/2006},
  Numpages                 = {30},
  Publisher                = {JMLR.org},
  Url                      = {http://dl.acm.org/citation.cfm?id=1248547.1248548}
}

@Article{FernandezCBA14,
  Title                    = {Do we Need Hundreds of Classifiers to Solve Real World Classification Problems?},
  Author                   = {Manuel Fern\'{a}ndez-Delgado and Eva Cernadas and Sen\'{e}n Barro and Dinani Amorim},
  Journal                  = {Journal of Machine Learning Research},
  Year                     = {2014},
  Pages                    = {3133--3181},
  Volume                   = {15},

  Url                      = {http://jmlr.org/papers/v15/delgado14a.html}
}

@InProceedings{FGH11,
  Title                    = {Addressing the Classification with Imbalanced Data: Open Problems and New Challenges on Class Distribution},
  Author                   = {Alberto Fern\'andez and Salvador Garc\'ia and Francisco Herrera},
  Booktitle                = {6th International Conference on Hybrid Artificial Intelligence Systems (HAIS)},
  Year                     = {2011},
  Pages                    = {1--10},

  Ee                       = {http://dx.doi.org/10.1007/978-3-642-21219-2_1}
}

@InProceedings{FlachHR11,
  Title                    = {A Coherent Interpretation of AUC as a Measure of Aggregated Classification Performance},
  Author                   = {Peter A. Flach and Jos{\'e} Hern{\'a}ndez-Orallo and C{\`e}sar Ferri Ramirez},
  Booktitle                = {Proceedings of the 28th International Conference on Machine Learning (ICML'11)},
  Year                     = {2011},

  Address                  = {Bellevue, Washington, USA},
  Month                    = {June 28- July 2, 2011},
  Pages                    = {657--664},

  Bibsource                = {DBLP, http://dblp.uni-trier.de}
}

@Article{freund1999short,
  Title                    = {A short introduction to boosting},
  Author                   = {Freund, Yoav and Schapire, Robert and Abe, Naoki},
  Journal                  = {Journal-Japanese Society For Artificial Intelligence},
  Year                     = {1999},
  Number                   = {771-780},
  Pages                    = {1612},
  Volume                   = {14},

  Publisher                = {JAPANESE SOC ARTIFICIAL INTELL}
}

@InProceedings{GrayBDSB11,
  Title                    = {The misuse of the NASA metrics data program data sets for automated software defect prediction},
  Author                   = {Gray, David and Bowes, David and Davey, Neil and Sun, Yi and Christianson, Bruce},
  Booktitle                = {Evaluation Assessment in Software Engineering (EASE 2011), 15th Annual Conference on},
  Year                     = {2011},
  Month                    = {april},
  Pages                    = {96 -103},

  Abstract                 = {Background: The NASA Metrics Data Program data sets have been heavily used in software defect prediction experiments. Aim: To demonstrate and explain why these data sets require significant pre-processing in order to be suitable for defect prediction. Method: A meticulously documented data cleansing process involving all 13 of the original NASA data sets. Results: Post our novel data cleansing process; each of the data sets had between 6 to 90 percent less of their original number of recorded values. Conclusions: One: Researchers need to analyse the data that forms the basis of their findings in the context of how it will be used. Two: Defect prediction data sets could benefit from lower level code metrics in addition to those more commonly used, as these will help to distinguish modules, reducing the likelihood of repeated data points. Three: The bulk of defect prediction experiments based on the NASA Metrics Data Program data sets may have led to erroneous findings. This is mainly due to repeated data points potentially causing substantial amounts of training and testing data to be identical.},
  Doi                      = {10.1049/ic.2011.0012}
}

@Article{HBBGC11,
  Title                    = {A Systematic Literature Review on Fault Prediction Performance in Software Engineering},
  Author                   = {Tracy Hall and Sarah Beecham and David Bowes and David Gray and Steve Counsell},
  Journal                  = {Transactions on Software Engineering},
  Year                     = {In Press -- 2011},

  Abstract                 = {Background: The accurate prediction of where faults are likely tooccur in code can help direct test effort, reduce costs and improve the quality of software. Objective: We investigate how the context of models, the independent variables used and the modelling techniques applied, influence the performance of fault prediction models.Method:We used a systematic literature review to identify 208 fault prediction studies published from January 2000 to December 2010. We synthesise the quantitative and qualitative results of 36 studies which report sufficient contextual and methodological information according to the criteria we develop and apply. Results: The models that perform well tend to be based on simple modelling techniques such as Na\F6\80\81\8Eve Bayes or Logistic Regression. Combinations of independent variables have been used by models thatperform well. Feature selection has been applied to these combinations when models are performing particularly well. Conclusion: The methodology used to build models seems to be influential to predictive performance. Although there are a set of fault prediction studies in which confidence is possible, more studies are needed that use a reliable methodology and which report theircontext, methodology and performance comprehensively.}
}

@Article{Hand09,
  Title                    = {Measuring classifier performance: a coherent alternative to the area under the ROC curve},
  Author                   = {Hand, David J.},
  Journal                  = {Machine Learning},
  Year                     = {2009},

  Month                    = oct,
  Number                   = {1},
  Pages                    = {103--123},
  Volume                   = {77},

  Acmid                    = {1613009},
  Address                  = {Hingham, MA, USA},
  Doi                      = {10.1007/s10994-009-5119-5},
  ISSN                     = {0885-6125},
  Issue_date               = {October 2009},
  Keywords                 = {AUC, Classification, Cost, Error rate, Loss, Misclassification rate, ROC curves, Sensitivity, Specificity},
  Numpages                 = {21},
  Publisher                = {Kluwer Academic Publishers},
  Url                      = {http://dx.doi.org/10.1007/s10994-009-5119-5}
}

@Article{He_KDE09_Imbalance,
  Title                    = {Learning from Imbalanced Data},
  Author                   = {Haibo He and E.A. Garcia},
  Journal                  = {IEEE Transactions on Knowledge and Data Engineering},
  Year                     = {2009},

  Month                    = {Sept.},
  Number                   = {9},
  Pages                    = {1263--1284},
  Volume                   = {21},

  Abstract                 = {With the continuous expansion of data availability in many large-scale, complex, and networked systems, such as surveillance, security, Internet, and finance, it becomes critical to advance the fundamental understanding of knowledge discovery and analysis from raw data to support decision-making processes. Although existing knowledge discovery and data engineering techniques have shown great success in many real-world applications, the problem of learning from imbalanced data (the imbalanced learning problem) is a relatively new challenge that has attracted growing attention from both academia and industry. The imbalanced learning problem is concerned with the performance of learning algorithms in the presence of underrepresented data and severe class distribution skews. Due to the inherent complex characteristics of imbalanced data sets, learning from such data requires new understandings, principles, algorithms, and tools to transform vast amounts of raw data efficiently into information and knowledge representation. In this paper, we provide a comprehensive review of the development of research in learning from imbalanced data. Our focus is to provide a critical review of the nature of the problem, the state-of-the-art technologies, and the current assessment metrics used to evaluate learning performance under the imbalanced learning scenario. Furthermore, in order to stimulate future research in this field, we also highlight the major opportunities and challenges, as well as potential important research directions for learning from imbalanced data.},
  Doi                      = {10.1109/TKDE.2008.239},
  ISSN                     = {1041-4347},
  Keywords                 = {complex systems;data availability;data engineering;decision making;imbalanced data;knowledge discovery;large-scale systems;learning;networked systems;data mining;decision making;large-scale systems;learning (artificial intelligence);}
}

@Article{HCGJ11,
  Title                    = {An overview on Subgroup Discovery: Foundations and Applications},
  Author                   = {Francisco Herrera and Crist\'{o}bal J. {Carmona del Jesus} and Pedro Gonz\'{a}lez and Mar\'{i}a Jos\'e {del Jesus}},
  Journal                  = {Knowledge and Information Systems},
  Year                     = {2011},
  Pages                    = {495--525},
  Volume                   = {29}
}

@Article{KL2006,
  Title                    = {{APRIORI-SD}: Adapting Association Rule Learning to Subgroup Discovery},
  Author                   = {Kav\v{s}ek, Branko and Lavra\v{c}, Nada},
  Journal                  = {Applied Artificial Intelligence},
  Year                     = {2006},
  Number                   = {7},
  Pages                    = {543-583},
  Volume                   = {20},

  Abstract                 = { This paper presents a subgroup discovery algorithm APRIORI-SD, developed by adapting association rule learning to subgroup discovery. The paper contributes to subgroup discovery, to a better understanding of the weighted covering algorithm, and the properties of the weighted relative accuracy heuristic by analyzing their performance in the ROC space. An experimental comparison with rule learners CN2, RIPPER, and APRIORI-C on UCI data sets demonstrates that APRIORI-SD produces substantially smaller rulesets, where individual rules have higher coverage and significance. APRIORI-SD is also compared to subgroup discovery algorithms CN2-SD and SubgroupMiner. The comparisons performed on U.K. traffic accident data show that APRIORI-SD is a competitive subgroup discovery algorithm. },
  Doi                      = {10.1080/08839510600779688},
  Eprint                   = {http://www.tandfonline.com/doi/pdf/10.1080/08839510600779688},
  Url                      = {http://www.tandfonline.com/doi/abs/10.1080/08839510600779688}
}

@Article{Khoshgoftaar09,
  Title                    = {Empirical Case Studies in Attribute Noise Detection},
  Author                   = {Khoshgoftaar, T.M. and Van Hulse, J.},
  Journal                  = {Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on},
  Year                     = {2009},

  Month                    = {july },
  Number                   = {4},
  Pages                    = {379 -388},
  Volume                   = {39},

  Abstract                 = {The quality of data is an important issue in any domain-specific data mining and knowledge discovery initiative. The validity of solutions produced by data-driven algorithms can be diminished if the data being analyzed are of low quality. The quality of data is often realized in terms of data noise present in the given dataset and can include noisy attributes or labeling errors. Hence, tools for improving the quality of data are important to the data mining analyst. We present a comprehensive empirical investigation of our new and innovative technique for ranking attributes in a given dataset from most to least noisy. Upon identifying the noisy attributes, specific treatments can be applied depending on how the data are to be used. In a classification setting, for example, if the class label is determined to contain the most noise, processes to cleanse this important attribute may be undertaken. Independent variables or predictors that have a low correlation to the class attribute and appear noisy may be eliminated from the analysis. Several case studies using both real-world and synthetic datasets are presented in this study. The noise detection performance is evaluated by injecting noise into multiple attributes at different noise levels. The empirical results demonstrate conclusively that our technique provides a very accurate and useful ranking of noisy attributes in a given dataset.},
  Doi                      = {10.1109/TSMCC.2009.2013815},
  ISSN                     = {1094-6977},
  Keywords                 = {attribute noise detection;data quality;domain-specific data mining;knowledge discovery;data analysis;data mining;}
}

@Article{KhoshgoftaarGN12,
  Title                    = {An Empirical Study of Feature Ranking Techniques for Software Quality Prediction},
  Author                   = {Taghi M. Khoshgoftaar and Kehan Gao and Amri Napolitano},
  Journal                  = {International Journal of Software Engineering and Knowledge Engineering},
  Year                     = {2012},
  Number                   = {2},
  Pages                    = {161-183},
  Volume                   = {22},

  Ee                       = {http://dx.doi.org/10.1142/S0218194012400013}
}

@Book{Klosgen96,
  Title                    = {Explora: a multipattern and multistrategy discovery assistant},
  Author                   = {Willi Kl\"osgen},
  Publisher                = {American Association for Artificial Intelligence},
  Year                     = {1996},

  Address                  = {Menlo Park, CA, USA},

  Book                     = {Advances in knowledge discovery and data mining},
  ISBN                     = {0-262-56097-6},
  Pages                    = {249--271}
}

@Article{Lavrac04,
  Title                    = {Subgroup Discovery with {CN2-SD}},
  Author                   = {Nada Lavra\v{c} and Branko Kav\v{s}ek and Peter Flach and Ljup\v{c}o Todorovski},
  Journal                  = {The Journal of Machine Learning Research},
  Year                     = {2004},
  Pages                    = {153--188},
  Volume                   = {5},

  Address                  = {Cambridge, MA, USA},
  ISSN                     = {1532-4435},
  Publisher                = {MIT Press}
}

@Article{Martinez2016,
  Title                    = {Improving a Multi-objective Evolutionary Algorithm to Discover Quantitative Association Rules},
  Author                   = {Mart\'{\i}nez-Ballesteros, M. and Troncoso, A. and Mart\'{\i}nez-\'{A}lvarez, F. and Riquelme, J. C.},
  Journal                  = {Knowl. Inf. Syst.},
  Year                     = {2016},

  Month                    = nov,
  Number                   = {2},
  Pages                    = {481--509},
  Volume                   = {49},

  Acmid                    = {3008257},
  Address                  = {New York, NY, USA},
  Doi                      = {10.1007/s10115-015-0911-y},
  ISSN                     = {0219-1377},
  Issue_date               = {November 2016},
  Keywords                 = {Association rules, Data mining, Evolutionary computation, Pareto-optimization},
  Numpages                 = {29},
  Publisher                = {Springer-Verlag New York, Inc.},
  Url                      = {http://dx.doi.org/10.1007/s10115-015-0911-y}
}

@InProceedings{Mende2010,
  Title                    = {Replication of defect prediction studies: problems, pitfalls and recommendations},
  Author                   = {Mende, Thilo},
  Booktitle                = {Proceedings of the 6th International Conference on Predictive Models in Software Engineering},
  Year                     = {2010},

  Address                  = {New York, NY, USA},
  Pages                    = {5:1--5:10},
  Publisher                = {ACM},
  Series                   = {PROMISE'10},

  Acmid                    = {1868336},
  Articleno                = {5},
  Doi                      = {10.1145/1868328.1868336},
  ISBN                     = {978-1-4503-0404-7},
  Keywords                 = {defect prediction model, replication},
  Location                 = {Timisoara, Romania},
  Numpages                 = {10},
  Url                      = {http://doi.acm.org/10.1145/1868328.1868336}
}

@InProceedings{Mende10,
  Title                    = {Effort-Aware Defect Prediction Models},
  Author                   = {Mende, Thilo and Koschke, Rainer},
  Booktitle                = {Proceedings of the 2010 14th European Conference on Software Maintenance and Reengineering (CSMR'10)},
  Year                     = {2010},

  Address                  = {Washington, DC, USA},
  Pages                    = {107--116},
  Publisher                = {IEEE Computer Society},
  Series                   = {CSMR'10},

  Acmid                    = {1955974},
  Doi                      = {10.1109/CSMR.2010.18},
  ISBN                     = {978-0-7695-4321-5},
  Keywords                 = {Defect Prediction Models, Evaluation, Cost-Benefits},
  Numpages                 = {10},
  Url                      = {http://dx.doi.org/10.1109/CSMR.2010.18}
}

@Article{RaudysJ91,
  Title                    = {Small sample size effects in statistical pattern recognition: recommendations for practitioners},
  Author                   = {Raudys, S.J. and Jain, A.K.},
  Journal                  = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  Year                     = {1991},

  Month                    = {mar},
  Number                   = {3},
  Pages                    = {252--264},
  Volume                   = {13},

  Doi                      = {10.1109/34.75512},
  ISSN                     = {0162-8828},
  Keywords                 = {classifiers;error estimation;error rates;feature selection;learning;sample size effects;statistical pattern recognition;pattern recognition;statistical analysis;}
}

@InProceedings{Rob10,
  Title                    = {Replicating {MSR}: A study of the potential replicability of papers published in the Mining Software Repositories proceedings},
  Author                   = {Robles, G.},
  Booktitle                = {7th IEEE Working Conference on Mining Software Repositories (MSR 2010)},
  Year                     = {2010},
  Month                    = {may},
  Pages                    = {171--180},

  Doi                      = {10.1109/MSR.2010.5463348},
  Keywords                 = {MSR;MSR replication;data sources;mining software repositories proceedings;potential replicability;software projects;data mining;}
}

@Article{RGIH09,
  Title                    = {Tools for the study of the usual data sources found in libre software projects},
  Author                   = {Gregorio Robles and Jesus M. Gonzalez-Barahona and Daniel Izquierdo-Cortazar and Israel Herraiz},
  Journal                  = {International Journal of Open Source Software and Processes},
  Year                     = {2009},

  Month                    = {Jan-March},
  Number                   = {1},
  Pages                    = {24--45},
  Volume                   = {1}
}

@Article{Shepperd2012,
  Title                    = {Evaluating prediction systems in software project estimation},
  Author                   = {Martin Shepperd and Steve MacDonell},
  Journal                  = {Information and Software Technology},
  Year                     = {2012},
  Pages                    = {-},

  Doi                      = {10.1016/j.infsof.2011.12.008},
  ISSN                     = {0950-5849}
}

