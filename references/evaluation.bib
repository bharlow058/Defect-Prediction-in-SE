@article{Fawcett2006,
title = "An introduction to ROC analysis",
journal = "Pattern Recognition Letters",
volume = "27",
number = "8",
pages = "861--874",
year = "2006",
note = "ROC Analysis in Pattern Recognition",
issn = "0167-8655",
doi = "http://dx.doi.org/10.1016/j.patrec.2005.10.010",
url = "http://www.sciencedirect.com/science/article/pii/S016786550500303X",
author = "Tom Fawcett",
keywords = "ROC analysis",
keywords = "Classifier evaluation",
keywords = "Evaluation metrics",
abstract = "Receiver operating characteristics (ROC) graphs are useful for organizing classifiers and visualizing their performance. ROC graphs are commonly used in medical decision making, and in recent years have been used increasingly in machine learning and data mining research. Although ROC graphs are apparently simple, there are some common misconceptions and pitfalls when using them in practice. The purpose of this article is to serve as an introduction to ROC graphs and as a guide for using them in research."
}


@BOOK{japkowicz2011evaluating,
  title = {Evaluating Learning Algorithms: A Classification Perspective},
  publisher = {Cambridge University Press},
  year = {2011},
  author = {Japkowicz, N. and Shah, M.},
  series = {Evaluating Learning Algorithms: A Classification Perspective},
  isbn = {9780521196000},
  lccn = {2010048733},
  url = {http://books.google.es/books?id=VoWIIOKVzR4C}
}


@Article{DrummondH2006,
author="Drummond, Chris and Holte, Robert C.",
title="Cost curves: An improved method for visualizing classifier performance",
journal="Machine Learning",
year="2006",
month="Oct",
day="01",
volume="65",
number="1",
pages="95--130",
abstract="This paper introduces cost curves, a graphical technique for visualizing the performance (error rate or expected cost) of 2-class classifiers over the full range of possible class distributions and misclassification costs. Cost curves are shown to be superior to ROC curves for visualizing classifier performance for most purposes. This is because they visually support several crucial types of performance assessment that cannot be done easily with ROC curves, such as showing confidence intervals on a classifier's performance, and visualizing the statistical significance of the difference in performance of two classifiers. A software tool supporting all the cost curve analysis described in this paper is available from the authors.",
issn="1573-0565",
doi="10.1007/s10994-006-8199-5",
url="http://dx.doi.org/10.1007/s10994-006-8199-5"
}


@inproceedings{Davis2006,
 author = {Davis, Jesse and Goadrich, Mark},
 title = {The Relationship Between Precision-Recall and ROC Curves},
 booktitle = {23rd International Conference on Machine Learning},
 series = {ICML'06},
 year = {2006},
 isbn = {1-59593-383-2},
 location = {Pittsburgh, Pennsylvania, USA},
 pages = {233--240},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1143844.1143874},
 doi = {10.1145/1143844.1143874},
 acmid = {1143874},
 publisher = {ACM},
 address = {New York, NY, USA},
} 


