<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Defect Prediction in Software Engineering</title>
  <meta name="description" content="Defect Prediction in Software Engineering">
  <meta name="generator" content="bookdown 0.4 and GitBook 2.6.7">

  <meta property="og:title" content="Defect Prediction in Software Engineering" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Defect Prediction in Software Engineering" />
  <meta name="github-repo" content="danrodgar/DefectPredictionSoftEng" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Defect Prediction in Software Engineering" />
  
  <meta name="twitter:description" content="Defect Prediction in Software Engineering" />
  

<meta name="author" content="Daniel Rodriguez and Javier Dolado">


<meta name="date" content="2017-07-06">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="settings-thresholds-for-defect-prediction.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Analysis in Software Engineering with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="part"><span><b>I Introduction to Software Engineering Defect Prediction</b></span></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="part"><span><b>II Data Sources and Metrics and Standards in Software Engineering Defect Prediction</b></span></li>
<li class="chapter" data-level="2" data-path="data-sources-in-software-engineering.html"><a href="data-sources-in-software-engineering.html"><i class="fa fa-check"></i><b>2</b> Data Sources in Software Engineering</a></li>
<li class="chapter" data-level="3" data-path="repositories.html"><a href="repositories.html"><i class="fa fa-check"></i><b>3</b> Repositories</a></li>
<li class="chapter" data-level="4" data-path="open-toolsdashboards-to-extract-data.html"><a href="open-toolsdashboards-to-extract-data.html"><i class="fa fa-check"></i><b>4</b> Open Tools/Dashboards to extract data</a><ul>
<li class="chapter" data-level="4.1" data-path="open-toolsdashboards-to-extract-data.html"><a href="open-toolsdashboards-to-extract-data.html#issues"><i class="fa fa-check"></i><b>4.1</b> Issues</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="metrics-in-software-enginering-prediction.html"><a href="metrics-in-software-enginering-prediction.html"><i class="fa fa-check"></i><b>5</b> Metrics in Software Enginering Prediction</a><ul>
<li class="chapter" data-level="5.1" data-path="metrics-in-software-enginering-prediction.html"><a href="metrics-in-software-enginering-prediction.html#complexity-metrics"><i class="fa fa-check"></i><b>5.1</b> Complexity Metrics</a><ul>
<li class="chapter" data-level="5.1.1" data-path="metrics-in-software-enginering-prediction.html"><a href="metrics-in-software-enginering-prediction.html#mccabes-complexity-measures"><i class="fa fa-check"></i><b>5.1.1</b> McCabe’s Complexity Measures</a></li>
<li class="chapter" data-level="5.1.2" data-path="metrics-in-software-enginering-prediction.html"><a href="metrics-in-software-enginering-prediction.html#halstead-s-software-science"><i class="fa fa-check"></i><b>5.1.2</b> Halstead-s Software Science</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="metrics-in-software-enginering-prediction.html"><a href="metrics-in-software-enginering-prediction.html#object-oriented-metrics"><i class="fa fa-check"></i><b>5.2</b> Object-Oriented Metrics</a></li>
<li class="chapter" data-level="5.3" data-path="metrics-in-software-enginering-prediction.html"><a href="metrics-in-software-enginering-prediction.html#churn-and-process-metrics"><i class="fa fa-check"></i><b>5.3</b> Churn and Process Metrics</a></li>
<li class="chapter" data-level="5.4" data-path="metrics-in-software-enginering-prediction.html"><a href="metrics-in-software-enginering-prediction.html#defect-standards"><i class="fa fa-check"></i><b>5.4</b> Defect Standards</a><ul>
<li class="chapter" data-level="5.4.1" data-path="metrics-in-software-enginering-prediction.html"><a href="metrics-in-software-enginering-prediction.html#ibms-orthogonal-defect-classificatoin-odc"><i class="fa fa-check"></i><b>5.4.1</b> IBM’s Orthogonal Defect Classificatoin (ODC)</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Machine Learning in Defect Prediction</b></span></li>
<li class="chapter" data-level="6" data-path="supervised-classification.html"><a href="supervised-classification.html"><i class="fa fa-check"></i><b>6</b> Supervised Classification</a><ul>
<li class="chapter" data-level="6.1" data-path="supervised-classification.html"><a href="supervised-classification.html#classification-trees"><i class="fa fa-check"></i><b>6.1</b> Classification Trees</a></li>
<li class="chapter" data-level="6.2" data-path="supervised-classification.html"><a href="supervised-classification.html#rules"><i class="fa fa-check"></i><b>6.2</b> Rules</a></li>
<li class="chapter" data-level="6.3" data-path="supervised-classification.html"><a href="supervised-classification.html#distanced-based-methods"><i class="fa fa-check"></i><b>6.3</b> Distanced-based Methods</a></li>
<li class="chapter" data-level="6.4" data-path="supervised-classification.html"><a href="supervised-classification.html#neural-networks"><i class="fa fa-check"></i><b>6.4</b> Neural Networks</a></li>
<li class="chapter" data-level="6.5" data-path="supervised-classification.html"><a href="supervised-classification.html#support-vector-machine"><i class="fa fa-check"></i><b>6.5</b> Support Vector Machine</a></li>
<li class="chapter" data-level="6.6" data-path="supervised-classification.html"><a href="supervised-classification.html#probabilistic-methods"><i class="fa fa-check"></i><b>6.6</b> Probabilistic Methods</a><ul>
<li class="chapter" data-level="6.6.1" data-path="supervised-classification.html"><a href="supervised-classification.html#naive-bayes"><i class="fa fa-check"></i><b>6.6.1</b> Naive Bayes</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="supervised-classification.html"><a href="supervised-classification.html#linear-discriminant-analysis-lda"><i class="fa fa-check"></i><b>6.7</b> Linear Discriminant Analysis (LDA)</a><ul>
<li class="chapter" data-level="6.7.1" data-path="supervised-classification.html"><a href="supervised-classification.html#predicting-the-number-of-defects-numerical-class"><i class="fa fa-check"></i><b>6.7.1</b> Predicting the number of defects (numerical class)</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="supervised-classification.html"><a href="supervised-classification.html#binary-logistic-regression-blr"><i class="fa fa-check"></i><b>6.8</b> Binary Logistic Regression (BLR)</a></li>
<li class="chapter" data-level="6.9" data-path="supervised-classification.html"><a href="supervised-classification.html#the-caret-package"><i class="fa fa-check"></i><b>6.9</b> The caret package</a></li>
<li class="chapter" data-level="6.10" data-path="supervised-classification.html"><a href="supervised-classification.html#ensembles"><i class="fa fa-check"></i><b>6.10</b> Ensembles</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html"><i class="fa fa-check"></i><b>7</b> Regression tecniques in Software defect prediction</a><ul>
<li class="chapter" data-level="7.1" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#zero-poison"><i class="fa fa-check"></i><b>7.1</b> Zero Poison</a><ul>
<li class="chapter" data-level="7.1.1" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#load-packages"><i class="fa fa-check"></i><b>7.1.1</b> Load packages</a></li>
<li class="chapter" data-level="7.1.2" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#the-number-of-software-defects.-count-data"><i class="fa fa-check"></i><b>7.1.2</b> The number of Software Defects. Count Data</a></li>
<li class="chapter" data-level="7.1.3" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#normal-regression"><i class="fa fa-check"></i><b>7.1.3</b> Normal Regression</a></li>
<li class="chapter" data-level="7.1.4" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#poisson-regression"><i class="fa fa-check"></i><b>7.1.4</b> Poisson Regression</a></li>
<li class="chapter" data-level="7.1.5" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#negative-binomial"><i class="fa fa-check"></i><b>7.1.5</b> Negative binomial</a></li>
<li class="chapter" data-level="7.1.6" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#zero-inflated-poisson-regression-zip"><i class="fa fa-check"></i><b>7.1.6</b> Zero-Inflated Poisson Regression ZIP</a></li>
<li class="chapter" data-level="7.1.7" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#zero-inflated-negative-binomial-zinb"><i class="fa fa-check"></i><b>7.1.7</b> Zero-Inflated Negative Binomial ZINB</a></li>
<li class="chapter" data-level="7.1.8" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#read-data"><i class="fa fa-check"></i><b>7.1.8</b> Read Data</a></li>
<li class="chapter" data-level="7.1.9" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#plot-histogram"><i class="fa fa-check"></i><b>7.1.9</b> Plot histogram</a></li>
<li class="chapter" data-level="7.1.10" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#correlation-among-variables"><i class="fa fa-check"></i><b>7.1.10</b> Correlation among variables</a></li>
<li class="chapter" data-level="7.1.11" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#classical-regression"><i class="fa fa-check"></i><b>7.1.11</b> Classical Regression</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#poisson-regression-1"><i class="fa fa-check"></i><b>7.2</b> Poisson Regression</a></li>
<li class="chapter" data-level="7.3" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#compare-to-null-model-intercept"><i class="fa fa-check"></i><b>7.3</b> Compare to Null Model (intercept)</a></li>
<li class="chapter" data-level="7.4" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#negative-binomial-1"><i class="fa fa-check"></i><b>7.4</b> Negative Binomial</a><ul>
<li class="chapter" data-level="7.4.1" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#zero-inflated-poisson"><i class="fa fa-check"></i><b>7.4.1</b> Zero Inflated Poisson</a></li>
<li class="chapter" data-level="7.4.2" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#zero-inflated-negative-binomial"><i class="fa fa-check"></i><b>7.4.2</b> Zero Inflated Negative Binomial</a></li>
<li class="chapter" data-level="7.4.3" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#comparing-models-with-vuong-test"><i class="fa fa-check"></i><b>7.4.3</b> Comparing models with Vuong test</a></li>
<li class="chapter" data-level="7.4.4" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#compute-confidence-intervals-for-intercept-and-variables.-zip-version"><i class="fa fa-check"></i><b>7.4.4</b> Compute Confidence Intervals for intercept and variables. ZIP version</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#compare-models-fit.-aic-and-bic"><i class="fa fa-check"></i><b>7.5</b> Compare Models Fit. AIC and BIC</a></li>
<li class="chapter" data-level="7.6" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#compare-prediction-of-defects"><i class="fa fa-check"></i><b>7.6</b> Compare prediction of Defects</a></li>
<li class="chapter" data-level="7.7" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#plot-predictions"><i class="fa fa-check"></i><b>7.7</b> Plot predictions</a></li>
<li class="chapter" data-level="7.8" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#regression-diagnostics"><i class="fa fa-check"></i><b>7.8</b> Regression diagnostics</a><ul>
<li class="chapter" data-level="7.8.1" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#cooks-d-for-the-zip"><i class="fa fa-check"></i><b>7.8.1</b> Cook’s D for the ZIP</a></li>
<li class="chapter" data-level="7.8.2" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#zip-model-variable-selection-for-the-equinox-using-aic-and-bic"><i class="fa fa-check"></i><b>7.8.2</b> ZIP Model variable selection for the Equinox using AIC and BIC</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="regression-tecniques-in-software-defect-prediction.html"><a href="regression-tecniques-in-software-defect-prediction.html#references-and-r-code-used"><i class="fa fa-check"></i><b>7.9</b> References and R code used</a></li>
</ul></li>
<li class="part"><span><b>IV Evaluation</b></span></li>
<li class="chapter" data-level="8" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html"><i class="fa fa-check"></i><b>8</b> Evaluation of Models</a><ul>
<li class="chapter" data-level="8.1" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#building-and-validating-a-model"><i class="fa fa-check"></i><b>8.1</b> Building and Validating a Model</a><ul>
<li class="chapter" data-level="8.1.1" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#holdout-approach"><i class="fa fa-check"></i><b>8.1.1</b> Holdout approach</a></li>
<li class="chapter" data-level="8.1.2" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#cross-validation-cv"><i class="fa fa-check"></i><b>8.1.2</b> Cross Validation (CV)</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#evaluation-of-classification-models"><i class="fa fa-check"></i><b>8.2</b> Evaluation of Classification Models</a><ul>
<li class="chapter" data-level="8.2.1" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#prediction-in-probabilistic-classifiers"><i class="fa fa-check"></i><b>8.2.1</b> Prediction in probabilistic classifiers</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#other-metrics-used-in-software-engineering-with-classification"><i class="fa fa-check"></i><b>8.3</b> Other Metrics used in Software Engineering with Classification</a></li>
<li class="chapter" data-level="8.4" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#graphical-evaluation"><i class="fa fa-check"></i><b>8.4</b> Graphical Evaluation</a><ul>
<li class="chapter" data-level="8.4.1" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#receiver-operating-characteristic-roc"><i class="fa fa-check"></i><b>8.4.1</b> Receiver Operating Characteristic (ROC)</a></li>
<li class="chapter" data-level="8.4.2" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#precision-recall-curve-prc"><i class="fa fa-check"></i><b>8.4.2</b> Precision-Recall Curve (PRC)</a></li>
<li class="chapter" data-level="8.4.3" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#cost-curves"><i class="fa fa-check"></i><b>8.4.3</b> Cost Curves</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#numeric-prediction-evaluation"><i class="fa fa-check"></i><b>8.5</b> Numeric Prediction Evaluation</a></li>
<li class="chapter" data-level="8.6" data-path="evaluation-of-models.html"><a href="evaluation-of-models.html#underfitting-vs.overfitting"><i class="fa fa-check"></i><b>8.6</b> Underfitting vs. Overfitting</a></li>
</ul></li>
<li class="part"><span><b>V Problems and Issues in Defect Prediction</b></span></li>
<li class="chapter" data-level="9" data-path="data-mining-issues-in-defect-prediction.html"><a href="data-mining-issues-in-defect-prediction.html"><i class="fa fa-check"></i><b>9</b> Data Mining Issues in Defect Prediction</a></li>
<li class="chapter" data-level="10" data-path="outliers-missing-values-inconsistencies-data-noise.html"><a href="outliers-missing-values-inconsistencies-data-noise.html"><i class="fa fa-check"></i><b>10</b> Outliers, missing values, inconsistencies data noise</a></li>
<li class="chapter" data-level="11" data-path="redundant-and-irrelevant-attributes-and-instances.html"><a href="redundant-and-irrelevant-attributes-and-instances.html"><i class="fa fa-check"></i><b>11</b> Redundant and irrelevant attributes and instances</a></li>
<li class="chapter" data-level="12" data-path="overlapping-or-class-separability.html"><a href="overlapping-or-class-separability.html"><i class="fa fa-check"></i><b>12</b> Overlapping or class separability</a></li>
<li class="chapter" data-level="13" data-path="data-shifting.html"><a href="data-shifting.html"><i class="fa fa-check"></i><b>13</b> Data shifting</a></li>
<li class="chapter" data-level="14" data-path="imbalance-datasets.html"><a href="imbalance-datasets.html"><i class="fa fa-check"></i><b>14</b> Imbalance datasets</a></li>
<li class="chapter" data-level="15" data-path="evaluation-metrics-and-the-evaluation-of-models.html"><a href="evaluation-metrics-and-the-evaluation-of-models.html"><i class="fa fa-check"></i><b>15</b> Evaluation metrics and the evaluation of models</a></li>
<li class="chapter" data-level="16" data-path="cross-project-defect-prediction.html"><a href="cross-project-defect-prediction.html"><i class="fa fa-check"></i><b>16</b> Cross project defect prediction</a></li>
<li class="part"><span><b>VI Examples</b></span></li>
<li class="chapter" data-level="17" data-path="feature-subsect-selection-in-defect-prediction.html"><a href="feature-subsect-selection-in-defect-prediction.html"><i class="fa fa-check"></i><b>17</b> Feature Subsect Selection in Defect Prediction</a></li>
<li class="chapter" data-level="18" data-path="imbalanced-data.html"><a href="imbalanced-data.html"><i class="fa fa-check"></i><b>18</b> Imbalanced data</a></li>
<li class="chapter" data-level="19" data-path="subgroup-discovery.html"><a href="subgroup-discovery.html"><i class="fa fa-check"></i><b>19</b> Subgroup Discovery</a></li>
<li class="chapter" data-level="20" data-path="semi-supervised-learning.html"><a href="semi-supervised-learning.html"><i class="fa fa-check"></i><b>20</b> Semi-supervised learning</a></li>
<li class="chapter" data-level="21" data-path="learning-from-crowds.html"><a href="learning-from-crowds.html"><i class="fa fa-check"></i><b>21</b> Learning from Crowds</a></li>
<li class="chapter" data-level="22" data-path="multi-objective-rules-for-defect-prediction.html"><a href="multi-objective-rules-for-defect-prediction.html"><i class="fa fa-check"></i><b>22</b> Multi-objective Rules for defect prediction</a></li>
<li class="chapter" data-level="23" data-path="settings-thresholds-for-defect-prediction.html"><a href="settings-thresholds-for-defect-prediction.html"><i class="fa fa-check"></i><b>23</b> Settings Thresholds for Defect Prediction</a><ul>
<li class="chapter" data-level="23.1" data-path="settings-thresholds-for-defect-prediction.html"><a href="settings-thresholds-for-defect-prediction.html#use-of-mean-and-standard-deviation"><i class="fa fa-check"></i><b>23.1</b> Use of Mean and Standard Deviation</a></li>
<li class="chapter" data-level="23.2" data-path="settings-thresholds-for-defect-prediction.html"><a href="settings-thresholds-for-defect-prediction.html#use-of-weighted-benchmark-data"><i class="fa fa-check"></i><b>23.2</b> Use of Weighted Benchmark Data</a></li>
<li class="chapter" data-level="23.3" data-path="settings-thresholds-for-defect-prediction.html"><a href="settings-thresholds-for-defect-prediction.html#use-of-quantiles"><i class="fa fa-check"></i><b>23.3</b> Use of Quantiles</a></li>
<li class="chapter" data-level="23.4" data-path="settings-thresholds-for-defect-prediction.html"><a href="settings-thresholds-for-defect-prediction.html#some-further-literature"><i class="fa fa-check"></i><b>23.4</b> Some further literature</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Defect Prediction in Software Engineering</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="references" class="section level1 unnumbered">
<h1>References</h1>

<div id="refs" class="references">
<div>
<p>Alves, T.L., C.Ypma, and J. Visser. 2010. “Deriving Metric Thresholds from Benchmark Data.” In <em>IEEE International Conference on Software Maintenance (Icsm’2010)</em>, 1–10. doi:<a href="https://doi.org/10.1109/ICSM.2010.5609747">10.1109/ICSM.2010.5609747</a>.</p>
</div>
<div>
<p>Arisholm, Erik, Lionel C. Briand, and Eivind B. Johannessen. 2010. “A Systematic and Comprehensive Investigation of Methods to Build and Evaluate Fault Prediction Models.” <em>Journal of Systems and Software</em> 83 (1). New York, NY, USA: Elsevier Science Inc.: 2–17. doi:<a href="https://doi.org/http://dx.doi.org/10.1016/j.jss.2009.06.055">http://dx.doi.org/10.1016/j.jss.2009.06.055</a>.</p>
</div>
<div>
<p>Bansiya, J., and C. G. Davis. 2002. “A Hierarchical Model for Object-Oriented Design Quality Assessment.” <em>IEEE Transactions on Software Engineering</em> 28 (1): 4–17. doi:<a href="https://doi.org/10.1109/32.979986">10.1109/32.979986</a>.</p>
</div>
<div>
<p>Benlarbi, S., K. El Emam, N. Goel, and S. Rai. 2000. “Thresholds for Object-Oriented Measures.” In <em>Proceedings 11th International Symposium on Software Reliability Engineering (Issre 2000)</em>, 24–38. doi:<a href="https://doi.org/10.1109/ISSRE.2000.885858">10.1109/ISSRE.2000.885858</a>.</p>
</div>
<div>
<p>Bowes, David, Tracy Hall, and Jean Petrić. 2015. “Different Classifiers Find Different Defects Although with Different Level of Consistency.” In <em>Proceedings of the 11th International Conference on Predictive Models and Data Analytics in Software Engineering (Promise’15</em>, 3:1–3:10. PROMISE’15. New York, NY, USA: ACM. doi:<a href="https://doi.org/10.1145/2810146.2810149">10.1145/2810146.2810149</a>.</p>
</div>
<div>
<p>Breiman, Leo. 1996. “Bagging Predictors.” <em>Machine Learning</em> 24 (2). Kluwer Academic Publishers: 123–40. doi:<a href="https://doi.org/10.1007/BF00058655">10.1007/BF00058655</a>.</p>
</div>
<div>
<p>Canfora, G., A. De Lucia, M. Di Penta, R. Oliveto, A. Panichella, and S. Panichella. 2013. “Multi-Objective Cross-Project Defect Prediction.” In <em>IEEE Sixth International Conference on Software Testing, Verification and Validation</em>, 252–61. doi:<a href="https://doi.org/10.1109/ICST.2013.38">10.1109/ICST.2013.38</a>.</p>
</div>
<div>
<p>Canfora, Gerardo, Andrea De Lucia, Massimiliano Di Penta, Rocco Oliveto, Annibale Panichella, and Sebastiano Panichella. 2015. “Defect Prediction as a Multiobjective Optimization Problem.” <em>Software Testing, Verification &amp; Reliability</em> 25 (4). Chichester, UK: John Wiley; Sons Ltd.: 426–59. doi:<a href="https://doi.org/10.1002/stvr.1570">10.1002/stvr.1570</a>.</p>
</div>
<div>
<p>Catal, Cagatay. 2011. “Software Fault Prediction: A Literature Review and Current Trends.” <em>Expert Systems with Applications</em> 38 (4): 4626–36. doi:<a href="https://doi.org/10.1016/j.eswa.2010.10.024">10.1016/j.eswa.2010.10.024</a>.</p>
</div>
<div>
<p>———. 2012. “Software Mining and Fault Prediction.” <em>Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery</em> 2 (5). John Wiley &amp; Sons, Inc.: 420–26. doi:<a href="https://doi.org/10.1002/widm.1067">10.1002/widm.1067</a>.</p>
</div>
<div>
<p>Catal, Cagatay, and Banu Diri. 2009. “A Systematic Review of Software Fault Prediction Studies.” <em>Expert Systems with Applications</em> 36 (4): 7346–54. doi:<a href="https://doi.org/10.1016/j.eswa.2008.10.027">10.1016/j.eswa.2008.10.027</a>.</p>
</div>
<div>
<p>Chidamber, S.R., and C.F. Kemerer. 1994. “A Metrics Suite for Object Oriented Design.” <em>IEEE Transactions on Software Engineering</em> 20 (6): 476–93. doi:<a href="https://doi.org/10.1109/32.295895">10.1109/32.295895</a>.</p>
</div>
<div>
<p>Davis, Jesse, and Mark Goadrich. 2006. “The Relationship Between Precision-Recall and Roc Curves.” In <em>23rd International Conference on Machine Learning</em>, 233–40. ICML’06. New York, NY, USA: ACM. doi:<a href="https://doi.org/10.1145/1143844.1143874">10.1145/1143844.1143874</a>.</p>
</div>
<div>
<p>Demšar, Janez. 2006. “Statistical Comparisons of Classifiers over Multiple Data Sets.” <em>Journal of Machine Learning Research</em> 7 (December). JMLR.org: 1–30. <a href="http://dl.acm.org/citation.cfm?id=1248547.1248548" class="uri">http://dl.acm.org/citation.cfm?id=1248547.1248548</a>.</p>
</div>
<div>
<p>Deocadez, Roger, Rachel Harrison, and Daniel Rodriguez. 2017. “Preliminary Study on Applying Semi-Supervised Learning to App Store Analysis.” In <em>Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering (Ease’17)</em>, 320–23. EASE’17. New York, NY, USA: ACM. doi:<a href="https://doi.org/10.1145/3084226.3084285">10.1145/3084226.3084285</a>.</p>
</div>
<div>
<p>Dolado, José Javier, Daniel Rodriguez, Mark Harman, William B. Langdon, and Federica Sarro. 2016. “Evaluation of Estimation Models Using the Minimum Interval of Equivalence.” <em>Applied Soft Computing</em> 49: 956–67. doi:<a href="https://doi.org/http://dx.doi.org/10.1016/j.asoc.2016.03.026">http://dx.doi.org/10.1016/j.asoc.2016.03.026</a>.</p>
</div>
<div>
<p>Drummond, Chris, and Robert C. Holte. 2006. “Cost Curves: An Improved Method for Visualizing Classifier Performance.” <em>Machine Learning</em> 65 (1): 95–130. doi:<a href="https://doi.org/10.1007/s10994-006-8199-5">10.1007/s10994-006-8199-5</a>.</p>
</div>
<div>
<p>D’Ambros, Marco, Michele Lanza, and Romain Robbes. 2010. “An Extensive Comparison of Bug Prediction Approaches.” In <em>Proceedings of the 7th Ieee Working Conference on Mining Software Repositories (Msr07)</em>, 31–41. IEEE CS Press.</p>
</div>
<div>
<p>D’Ambros, Marco, Michele Lanza, and Romain Robbes. 2011. “Evaluating Defect Prediction Approaches: A Benchmark and an Extensive Comparison.” <em>Empirical Software Engineering</em>. Springer Netherlands, 1–47.</p>
</div>
<div>
<p>Fawcett, Tom. 2006. “An Introduction to Roc Analysis.” <em>Pattern Recognition Letters</em> 27 (8): 861–74. doi:<a href="https://doi.org/http://dx.doi.org/10.1016/j.patrec.2005.10.010">http://dx.doi.org/10.1016/j.patrec.2005.10.010</a>.</p>
</div>
<div>
<p>Fernández, Alberto, Salvador García, and Francisco Herrera. 2011. “Addressing the Classification with Imbalanced Data: Open Problems and New Challenges on Class Distribution.” In <em>6th International Conference on Hybrid Artificial Intelligence Systems (Hais)</em>, 1–10.</p>
</div>
<div>
<p>Fernández-Delgado, Manuel, Eva Cernadas, Senén Barro, and Dinani Amorim. 2014. “Do We Need Hundreds of Classifiers to Solve Real World Classification Problems?” <em>Journal of Machine Learning Research</em> 15: 3133–81. <a href="http://jmlr.org/papers/v15/delgado14a.html" class="uri">http://jmlr.org/papers/v15/delgado14a.html</a>.</p>
</div>
<div>
<p>Freund, Yoav, Robert Schapire, and Naoki Abe. 1999. “A Short Introduction to Boosting.” <em>Journal-Japanese Society For Artificial Intelligence</em> 14 (771-780). JAPANESE SOC ARTIFICIAL INTELL: 1612.</p>
</div>
<div>
<p>Gray, D., D. Bowes, N. Davey, Y. Sun, and B. Christianson. 2011a. “Further Thoughts on Precision.” In <em>15th Annual Conference on Evaluation Assessment in Software Engineering (Ease 2011)</em>, 129–33. doi:<a href="https://doi.org/10.1049/ic.2011.0016">10.1049/ic.2011.0016</a>.</p>
</div>
<div>
<p>———. 2011b. “The Misuse of the Nasa Metrics Data Program Data Sets for Automated Software Defect Prediction.” In <em>15th Annual Conference on Evaluation Assessment in Software Engineering (Ease 2011)</em>, 96–103. doi:<a href="https://doi.org/10.1049/ic.2011.0012">10.1049/ic.2011.0012</a>.</p>
</div>
<div>
<p>Gray, David, David Bowes, Neil Davey, Yi Sun, and Bruce Christianson. 2011. “The Misuse of the Nasa Metrics Data Program Data Sets for Automated Software Defect Prediction.” In <em>Evaluation Assessment in Software Engineering (Ease 2011), 15th Annual Conference on</em>, 96–103. doi:<a href="https://doi.org/10.1049/ic.2011.0012">10.1049/ic.2011.0012</a>.</p>
</div>
<div>
<p>Hall, T., S. Beecham, D. Bowes, D. Gray, and S. Counsell. 2012. “A Systematic Literature Review on Fault Prediction Performance in Software Engineering.” <em>IEEE Transactions on Software Engineering</em> 38 (6): 1276–1304. doi:<a href="https://doi.org/10.1109/TSE.2011.103">10.1109/TSE.2011.103</a>.</p>
</div>
<div>
<p>Halstead, M.H. 1977. <em>Elements of Software Science</em>. Elsevier Computer Science Library. Operating and Programming Systems Series; 2. New York ; Oxford: Elsevier.</p>
</div>
<div>
<p>Hand, David J. 2009. “Measuring Classifier Performance: A Coherent Alternative to the Area Under the Roc Curve.” <em>Machine Learning</em> 77 (1). Hingham, MA, USA: Kluwer Academic Publishers: 103–23. doi:<a href="https://doi.org/10.1007/s10994-009-5119-5">10.1007/s10994-009-5119-5</a>.</p>
</div>
<div>
<p>He, Haibo, and E.A. Garcia. 2009. “Learning from Imbalanced Data.” <em>IEEE Transactions on Knowledge and Data Engineering</em> 21 (9): 1263–84. doi:<a href="https://doi.org/10.1109/TKDE.2008.239">10.1109/TKDE.2008.239</a>.</p>
</div>
<div>
<p>Herraiz, Israel, Daniel Izquierdo-Cortazar, Francisco Rivas-Hernandez, Jesus M. Gonzalez-Barahona, Gregorio Robles, Santiago Dueñas Dominguez, Carlos Garcia-Campos, Juan Francisco Gato, and Liliana Tovar. 2009. “FLOSSMetrics: Free / Libre / Open Source Software Metrics.” In <em>Proceedings of the 13th European Conference on Software Maintenance and Reengineering (Csmr)</em>. Kaiserlauten, Germany: IEEE Computer Society.</p>
</div>
<div>
<p>Herrera, Francisco, Cristóbal J. Carmona del Jesus, Pedro González, and María José del Jesus. 2011. “An Overview on Subgroup Discovery: Foundations and Applications.” <em>Knowledge and Information Systems</em> 29: 495–525.</p>
</div>
<div>
<p>Hosseini, Seyedrebvar, Burak Turhan, and Mika Mantyla. 2017. “A Benchmark Study on the Effectiveness of Search-Based Data Selection and Feature Selection for Cross Project Defect Prediction.” <em>Information and Software Technology</em>, –. doi:<a href="https://doi.org/https://doi.org/10.1016/j.infsof.2017.06.004">https://doi.org/10.1016/j.infsof.2017.06.004</a>.</p>
</div>
<div>
<p>Howison, James, Megan Conklin, and Kevin Crowston. 2006. “FLOSSmole: A Collaborative Repository for FLOSS Research Data and Analyses.” <em>International Journal of Information Technology and Web Engineering</em> 1 (3). doi:<a href="https://doi.org/10.4018/jitwe.2006070102">10.4018/jitwe.2006070102</a>.</p>
</div>
<div>
<p>Huang, LiGuo, V. Ng, I. Persing, Ruili Geng, Xu Bai, and Jeff Tian. 2011. “AutoODC: Automated Generation of Orthogonal Defect Classifications.” In <em>26th Ieee/Acm International Conference on Automated Software Engineering (Ase’2011)</em>, 412–15. doi:<a href="https://doi.org/10.1109/ASE.2011.6100086">10.1109/ASE.2011.6100086</a>.</p>
</div>
<div>
<p>Ibarguren, Igor, J.M. Pérez, Javier Muguerza, Daniel Rodriguez, and Rachel Harrison. 2017. “The Consolidated Tree Construction Algorithm in Imbalanced Defect Prediction Datasets.” In <em>Evolutionary Methods and Machine Learning in Se, Testing and Se Repositories. Proceedings of the 2017 Ieee Congress on Evolutionary Computation (Cec2017)</em>, 96–103.</p>
</div>
<div>
<p>Jiang, Y., B. Cukic, and T. Menzies. 2008. “Cost Curve Evaluation of Fault Prediction Models.” In <em>19th International Symposium on Software Reliability Engineering (Issre)</em>, 197–206. doi:<a href="https://doi.org/10.1109/ISSRE.2008.54">10.1109/ISSRE.2008.54</a>.</p>
</div>
<div>
<p>Jiang, Yue, Bojan Cukic, and Yan Ma. 2008. “Techniques for Evaluating Fault Prediction Models.” <em>Empirical Software Engineering</em> 13 (5): 561–95. doi:<a href="https://doi.org/10.1007/s10664-008-9079-3">10.1007/s10664-008-9079-3</a>.</p>
</div>
<div>
<p>Jureczko, Marian, and Diomidis Spinellis. 2010. “Using Object-Oriented Design Metrics to Predict Software Defects.” In <em>Models and Methodology of System Dependability. Proceedings of RELCOMEX 2010 Fifth International Conference on Dependability of Computer Systems DepCoS</em>, 69–81. Monographs of System Dependability. Wrocław, Poland: Oficyna Wydawnicza Politechniki Wrocławskiej. <a href="http://www.dmst.aueb.gr/dds/pubs/conf/2010-DepCoS-RELCOMEX-ckjm-defects/html/JS10.html" class="uri">http://www.dmst.aueb.gr/dds/pubs/conf/2010-DepCoS-RELCOMEX-ckjm-defects/html/JS10.html</a>.</p>
</div>
<div>
<p>Khoshgoftaar, T.M., and J. Van Hulse. 2009. “Empirical Case Studies in Attribute Noise Detection.” <em>Systems, Man, and Cybernetics, Part C: Applications and Reviews, IEEE Transactions on</em> 39 (4): 379–88. doi:<a href="https://doi.org/10.1109/TSMCC.2009.2013815">10.1109/TSMCC.2009.2013815</a>.</p>
</div>
<div>
<p>Khoshgoftaar, Taghi M., Kehan Gao, and Amri Napolitano. 2012a. “An Empirical Study of Feature Ranking Techniques for Software Quality Prediction.” <em>International Journal of Software Engineering and Knowledge Engineering</em> 22 (2): 161–83.</p>
</div>
<div>
<p>———. 2012b. “Exploring an Iterative Feature Selection Technique for Highly Imbalanced Data Sets.” In <em>IEEE 13th International Conference on Information Reuse and Integration (Iri’2012)</em>, 101–8. doi:<a href="https://doi.org/10.1109/IRI.2012.6302997">10.1109/IRI.2012.6302997</a>.</p>
</div>
<div>
<p>Kim, Sunghun, Thomas Zimmermann, Kai Pan, and E. James Jr. Whitehead. 2006. “Automatic Identification of Bug-Introducing Changes.” In <em>Proceedings of the 21st Ieee/Acm International Conference on Automated Software Engineering</em>, 81–90. ASE’06. Washington, DC, USA: IEEE Computer Society. doi:<a href="https://doi.org/10.1109/ASE.2006.23">10.1109/ASE.2006.23</a>.</p>
</div>
<div>
<p>Klösgen, Willi. 1996. <em>Explora: A Multipattern and Multistrategy Discovery Assistant</em>. Menlo Park, CA, USA: American Association for Artificial Intelligence.</p>
</div>
<div>
<p>Krishnan, Sandeep, Chris Strasburg, Robyn R. Lutz, and Katerina Goševa-Popstojanova. 2011. “Are Change Metrics Good Predictors for an Evolving Software Product Line?” In <em>Proceedings of the 7th International Conference on Predictive Models in Software Engineering (Promise’11)</em>, 7:1–7:10. Promise’11. New York, NY, USA: ACM. doi:<a href="https://doi.org/10.1145/2020390.2020397">10.1145/2020390.2020397</a>.</p>
</div>
<div>
<p>Li, Ming, Hongyu Zhang, Rongxin Wu, and Zhi-Hua Zhou. 2012. “Sample-Based Software Defect Prediction with Active and Semi-Supervised Learning.” <em>Automated Software Engineering</em> 19 (2): 201–30. doi:<a href="https://doi.org/10.1007/s10515-011-0092-1">10.1007/s10515-011-0092-1</a>.</p>
</div>
<div>
<p>Lincke, Rüdiger, Jonas Lundberg, and Welf Löwe. 2008. “Comparing Software Metrics Tools.” In <em>Proceedings of the 2008 International Symposium on Software Testing and Analysis (Issta’08)</em>, 131–42. ISSTA’08. New York, NY, USA: ACM. doi:<a href="https://doi.org/10.1145/1390630.1390648">10.1145/1390630.1390648</a>.</p>
</div>
<div>
<p>Linstead, Erik, Sushil Bajracharya, Trung Ngo, Paul Rigor, Cristina Lopes, and Pierre Baldi. 2009. “Sourcerer: Mining and Searching Internet-Scale Software Repositories.” <em>Data Mining and Knowledge Discovery</em> 18 (2). Springer Netherlands: 300–336.</p>
</div>
<div>
<p>Lu, H., B. Cukic, and M. Culp. 2012. “Software Defect Prediction Using Semi-Supervised Learning with Dimension Reduction.” In <em>27th Ieee/Acm International Conference on Automated Software Engineering (Ase’12)</em>, 314–17. doi:<a href="https://doi.org/10.1145/2351676.2351734">10.1145/2351676.2351734</a>.</p>
</div>
<div>
<p>Madeyski, Lech, and Marian Jureczko. 2015. “Which Process Metrics Can Significantly Improve Defect Prediction Models? An Empirical Study.” <em>Software Quality Journal</em> 23 (3): 393–422. doi:<a href="https://doi.org/10.1007/s11219-014-9241-7">10.1007/s11219-014-9241-7</a>.</p>
</div>
<div>
<p>Martínez-Ballesteros, M., A. Troncoso, F. Martínez-Álvarez, and J. C. Riquelme. 2016. “Improving a Multi-Objective Evolutionary Algorithm to Discover Quantitative Association Rules.” <em>Knowl. Inf. Syst.</em> 49 (2). New York, NY, USA: Springer-Verlag New York, Inc.: 481–509. doi:<a href="https://doi.org/10.1007/s10115-015-0911-y">10.1007/s10115-015-0911-y</a>.</p>
</div>
<div>
<p>Matthews, B. W. 1975. “Comparison of the Predicted and Observed Secondary Structure of T4 Phage Lysozyme.” <em>Biochimica et Biophysica Acta</em> 405 (2): 442–51. <a href="http://view.ncbi.nlm.nih.gov/pubmed/1180967" class="uri">http://view.ncbi.nlm.nih.gov/pubmed/1180967</a>.</p>
</div>
<div>
<p>McCabe, T.J. 1976. “A Complexity Measure.” <em>IEEE Transactions on Software Engineering</em> 2 (4): 308–20.</p>
</div>
<div>
<p>Mende, Thilo, and Rainer Koschke. 2010. “Effort-Aware Defect Prediction Models.” In <em>Proceedings of the 2010 14th European Conference on Software Maintenance and Reengineering (Csmr’10)</em>, 107–16. CSMR’10. Washington, DC, USA: IEEE Computer Society. doi:<a href="https://doi.org/10.1109/CSMR.2010.18">10.1109/CSMR.2010.18</a>.</p>
</div>
<div>
<p>Menzies, T., J. Greenwald, and A. Frank. 2007. “Data Mining Static Code Attributes to Learn Defect Predictors.” <em>IEEE Transactions on Software Engineering</em>.</p>
</div>
<div>
<p>Menzies, Tim, Alex Dekhtyar, Justin Distefano, and Jeremy Greenwald. 2007. “Problems with Precision: A Response to Comments on Data Mining Static Code Attributes to Learn Defect Predictors.” <em>IEEE Transactions on Software Engineering</em> 33 (9). Los Alamitos, CA, USA: IEEE Computer Society: 637–40. doi:<a href="https://doi.org/http://doi.ieeecomputersociety.org/10.1109/TSE.2007.70721">http://doi.ieeecomputersociety.org/10.1109/TSE.2007.70721</a>.</p>
</div>
<div>
<p>Morasca, Sandro, and Luigi Lavazza. 2016. “Slope-Based Fault-Proneness Thresholds for Software Engineering Measures.” In <em>Proceedings of the 20th International Conference on Evaluation and Assessment in Software Engineering</em>, 12:1–12:10. EASE ’16. New York, NY, USA: ACM. doi:<a href="https://doi.org/10.1145/2915970.2915997">10.1145/2915970.2915997</a>.</p>
</div>
<div>
<p>Moser, R., W. Pedrycz, and G. Succi. 2008. “A Comparative Analysis of the Efficiency of Change Metrics and Static Code Attributes for Defect Prediction.” In <em>2008 Acm/Ieee 30th International Conference on Software Engineering</em>, 181–90. doi:<a href="https://doi.org/10.1145/1368088.1368114">10.1145/1368088.1368114</a>.</p>
</div>
<div>
<p>Nagappan, Nachiappan, Andreas Zeller, Thomas Zimmermann, Kim Herzig, and Brendan Murphy. 2012. “Change Bursts as Defect Predictors.” In <em>21st Ieee International Symposium on Software Reliability Engineering (Issre 2012)</em>. San Jose, California, USA.</p>
</div>
<div>
<p>Nussbaum, L., and S. Zacchiroli. 2010. “The Ultimate Debian Database: Consolidating Bazaar Metadata for Quality Assurance and Data Mining.” In <em>7th Ieee Working Conference on Mining Software Repositories (Msr 2010)</em>, 52–61. doi:<a href="https://doi.org/10.1109/MSR.2010.5463277">10.1109/MSR.2010.5463277</a>.</p>
</div>
<div>
<p>Panichella, A., R. Oliveto, and A. De Lucia. 2014. “Cross-Project Defect Prediction Models: L’Union Fait La Force.” In <em>2014 Software Evolution Week - Ieee Conference on Software Maintenance, Reengineering, and Reverse Engineering (Csmr-Wcre)</em>, 164–73. doi:<a href="https://doi.org/10.1109/CSMR-WCRE.2014.6747166">10.1109/CSMR-WCRE.2014.6747166</a>.</p>
</div>
<div>
<p>Raudys, S.J., and A.K. Jain. 1991. “Small Sample Size Effects in Statistical Pattern Recognition: Recommendations for Practitioners.” <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em> 13 (3): 252–64. doi:<a href="https://doi.org/10.1109/34.75512">10.1109/34.75512</a>.</p>
</div>
<div>
<p>Rodriguez, D., R. Ruiz, J. Cuadrado, and J. Aguilar-Ruiz. 2007. “Detecting Fault Modules Applying Feature Selection to Classifiers.” In <em>IEEE International Conference on Information Reuse and Integration (Iri 2007)</em>, 667–72. doi:<a href="https://doi.org/10.1109/IRI.2007.4296696">10.1109/IRI.2007.4296696</a>.</p>
</div>
<div>
<p>Rodriguez, D., R. Ruiz, J.C. Riquelme, and J.S. Aguilarâ€“Ruiz. 2012. “Searching for Rules to Detect Defective Modules: A Subgroup Discovery Approach.” <em>Information Sciences</em> 191 (0): 14–30. doi:<a href="https://doi.org/10.1016/j.ins.2011.01.039">10.1016/j.ins.2011.01.039</a>.</p>
</div>
<div>
<p>Seiffert, C., T.M. Khoshgoftaar, J. Van Hulse, and A. Folleco. 2007. “An Empirical Study of the Classification Performance of Learners on Imbalanced and Noisy Software Quality Data.” In <em>2007 Ieee International Conference on Information Reuse and Integration, Ieee Iri-2007</em>, 651–58.</p>
</div>
<div>
<p>Shepperd, M., Qinbao Song, Zhongbin Sun, and C. Mair. 2013. “Data Quality: Some Comments on the Nasa Software Defect Datasets.” <em>IEEE Transactions on Software Engineering</em> 39 (9): 1208–15. doi:<a href="https://doi.org/10.1109/TSE.2013.11">10.1109/TSE.2013.11</a>.</p>
</div>
<div>
<p>Shippey, Thomas, Tracy Hall, Steve Counsell, and David Bowes. 2016. “So You Need More Method Level Datasets for Your Software Defect Prediction? Voila!” In <em>10th Acm/Ieee International Symposium on Empirical Software Engineering and Measurement (Esem’16)</em>, 12:1–12:6. ESEM’16. New York, NY, USA: ACM. doi:<a href="https://doi.org/10.1145/2961111.2962620">10.1145/2961111.2962620</a>.</p>
</div>
<div>
<p>Śliwerski, Jacek, Thomas Zimmermann, and Andreas Zeller. 2005. “When Do Changes Induce Fixes?” In <em>Proceedings of the 2005 International Workshop on Mining Software Repositories</em>, 1–5. MSR’05. New York, NY, USA: ACM. doi:<a href="https://doi.org/10.1145/1082983.1083147">10.1145/1082983.1083147</a>.</p>
</div>
<div>
<p>Tempero, Ewan, Craig Anslow, Jens Dietrich, Ted Han, Jing Li, Markus Lumpe, Hayden Melton, and James Noble. 2010. “Qualitas Corpus: A Curated Collection of Java Code for Empirical Studies.” In <em>2010 Asia Pacific Software Engineering Conference (Apsec2010)</em>.</p>
</div>
<div>
<p>Turhan, Burak. 2012. “On the Dataset Shift Problem in Software Engineering Prediction Models.” <em>Empirical Software Engineering</em> 17 (1). Springer Netherlands: 62–74.</p>
</div>
<div>
<p>Van Antwerp, M., and G. Madey. 2008. “Advances in the Sourceforge Research Data Archive (Srda).” Milan, Italy.</p>
</div>
<div>
<p>Vasa, Rajesh. 2010. “Growth and Change Dynamics in Open Source Software Systems.” PhD thesis, Faculty of Information; Communication Technologies Swinburne University of Technology Melbourne, Australia.</p>
</div>
<div>
<p>Wang, Huanjing, Taghi M. Khoshgoftaar, Randall Wald, and Amri Napolitano. 2012. “A Comparative Study on the Stability of Software Metric Selection Techniques.” In <em>11th International Conference on Machine Learning and Applications, Icmla</em>, 301–7.</p>
</div>
<div>
<p>Wrobel, Stefan. 1997. “An Algorithm for Multi-Relational Discovery of Subgroups.” In <em>Proceedings of the 1st European Symposium on Principles of Data Mining</em>, 78–87.</p>
</div>
<div>
<p>———. 2001. “Relational Data Mining.” In, edited by Saso Dzeroski and Nada Lavrac, 74–101. Springer.</p>
</div>
<div>
<p>Zhang, H. 2009. “An Investigation of the Relationships Between Lines of Code and Defects.” In <em>IEEE International Conference on Software Maintenance</em>, 274–83. doi:<a href="https://doi.org/10.1109/ICSM.2009.5306304">10.1109/ICSM.2009.5306304</a>.</p>
</div>
<div>
<p>Zhang, Hongyu, and Xiuzhen Zhang. 2007. “Comments on ‘Data Mining Static Code Attributes to Learn Defect Predictors’.” <em>IEEE Transactions on Software Engineering</em> 33 (9). Los Alamitos, CA, USA: IEEE Computer Society: 635–37. doi:<a href="https://doi.org/http://doi.ieeecomputersociety.org/10.1109/TSE.2007.70706">http://doi.ieeecomputersociety.org/10.1109/TSE.2007.70706</a>.</p>
</div>
<div>
<p>Zimmermann, Thomas, Nachiappan Nagappan, Harald Gall, Emanuel Giger, and Brendan Murphy. 2009. “Cross-Project Defect Prediction: A Large Scale Experiment on Data Vs. Domain Vs. Process.” In <em>Proceedings of the the 7th Joint Meeting of the European Software Engineering Conference and the Acm Sigsoft Symposium on the Foundations of Software Engineering</em>, 91–100. ESEC/Fse’09. New York, NY, USA: ACM. doi:<a href="https://doi.org/10.1145/1595696.1595713">10.1145/1595696.1595713</a>.</p>
</div>
<div>
<p>Zimmermann, Thomas, Rahul Premraj, and Andreas Zeller. 2007. “Predicting Defects for Eclipse.” In <em>Proceedings of the Third International Workshop on Predictor Models in Software Engineering (Promise’07)</em>, 9. PROMISE ’07. Washington, DC, USA: IEEE Computer Society. doi:<a href="https://doi.org/http://dx.doi.org/10.1109/PROMISE.2007.10">http://dx.doi.org/10.1109/PROMISE.2007.10</a>.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="settings-thresholds-for-defect-prediction.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/danrodgar/dasedown/edit/master/999_references.Rmd",
"text": "Edit"
},
"download": ["DefectPredictionSoftEng.pdf", "DefectPredictionSoftEng.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
